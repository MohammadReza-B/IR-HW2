{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='skyblue'>HW-1 + HW-2 _ Information Retrieval\n",
    "\n",
    "MohammadReza\n",
    "\n",
    "May - 2023\n",
    "<font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import re\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Opening stopword.txt file and store each word in a list.</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords: 542\n",
      "Some of stopwords: \n",
      " ['a', 'associates', 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after']\n"
     ]
    }
   ],
   "source": [
    "with open('stopwords.txt', 'r') as stopwords_file:\n",
    "    stopwords = stopwords_file.read().split()\n",
    "\n",
    "\n",
    "print('Number of stopwords:', len(stopwords))\n",
    "print('Some of stopwords: \\n', stopwords[0:10])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='yellow'>-----------------------PART 1: PARSING-----------------------</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening 3 folders:\n",
    "\n",
    "#### 2007, 2008, 2009\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 2007 cars:  227\n",
      "Number of 2008 cars:  228\n",
      "Number of 2009 cars:  143\n",
      "Number of all cars:  598\n"
     ]
    }
   ],
   "source": [
    "# Use the os module to get a list of all files in the folder.\n",
    "import os\n",
    "path_2007 = './cars/2007'\n",
    "car_2007_names = os.listdir(path_2007)\n",
    "print('Number of 2007 cars: ', len(car_2007_names))\n",
    "\n",
    "path_2008 = './cars/2008'\n",
    "car_2008_names = os.listdir(path_2008)\n",
    "print('Number of 2008 cars: ', len(car_2008_names))\n",
    "\n",
    "path_2009 = './cars/2009'\n",
    "car_2009_names = os.listdir(path_2009)\n",
    "print('Number of 2009 cars: ', len(car_2009_names))\n",
    "\n",
    "print('Number of all cars: ', len(car_2007_names) + len(car_2008_names) + len(car_2009_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = []\n",
    "favorite_list = []\n",
    "doc_id_list = []\n",
    "car_names = []\n",
    "doc_id = 11111\n",
    "\n",
    "def reset_list():\n",
    "    global text_list, favorite_list, doc_id_list, car_names, doc_id\n",
    "    text_list = []\n",
    "    favorite_list = []\n",
    "    doc_id_list = []\n",
    "    car_names = []\n",
    "    doc_id = 11111\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_list(file_name, data):\n",
    "    global text_list, favorite_list, doc_id_list, car_names, doc_id\n",
    "\n",
    "    doc_regex = re.compile(r'<DOC>.*?</DOC>', re.DOTALL)\n",
    "    doc_matches = doc_regex.findall(data)\n",
    "\n",
    "    for match in doc_matches:\n",
    "        text_regex = re.compile(r'<TEXT>(.*?)</TEXT>')\n",
    "        text_match = text_regex.search(match)\n",
    "        if text_match:\n",
    "            text_list.append(text_match.group(1))\n",
    "            car_names.append(file_name)\n",
    "            # doc_id_list.append(file_name + '_' + str(doc_id))\n",
    "            doc_id_list.append(file_name[0:4] + str(doc_id))  # new\n",
    "            doc_id += 1\n",
    "        else:\n",
    "            text_list.append(\" \")\n",
    "            car_names.append(file_name)\n",
    "            # doc_id_list.append(file_name + '_' + str(doc_id))\n",
    "            doc_id_list.append(file_name[0:4] + str(doc_id))  # new\n",
    "            doc_id += 1\n",
    "\n",
    "        fav_regex = re.compile(r'<FAVORITE>(.*?)</FAVORITE>')\n",
    "        fav_match = fav_regex.search(match)\n",
    "        if fav_match:\n",
    "            favorite_list.append(fav_match.group(1))\n",
    "        else:\n",
    "            favorite_list.append(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_2007_DOC = pd.DataFrame()\n",
    "cars_2008_DOC = pd.DataFrame()\n",
    "cars_2009_DOC = pd.DataFrame()\n",
    "\n",
    "\n",
    "def make_df(year):\n",
    "    # Create a Pandas DataFrame from the lists\n",
    "    global cars_2007_DOC\n",
    "    global cars_2008_DOC\n",
    "    global cars_2009_DOC\n",
    "    if year == 2007:\n",
    "        cars_2007_DOC = pd.DataFrame({\n",
    "            'CAR_NAME': car_names,\n",
    "            'DOCID': doc_id_list,\n",
    "            'TEXT': text_list,\n",
    "            'FAVORITE': favorite_list\n",
    "        })\n",
    "\n",
    "    elif year == 2008:\n",
    "        cars_2008_DOC = pd.DataFrame({\n",
    "            'CAR_NAME': car_names,\n",
    "            'DOCID': doc_id_list,\n",
    "            'TEXT': text_list,\n",
    "            'FAVORITE': favorite_list\n",
    "        })\n",
    "    elif year == 2009:\n",
    "        cars_2009_DOC = pd.DataFrame({\n",
    "            'CAR_NAME': car_names,\n",
    "            'DOCID': doc_id_list,\n",
    "            'TEXT': text_list,\n",
    "            'FAVORITE': favorite_list\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the chardet library to detect the encoding of the file.\n",
    "import chardet\n",
    "\n",
    "\"\"\" \n",
    "  The first part of the code reads the file in binary mode and uses chardet to detect the encoding.\n",
    "  The second part of the code reads the file in text mode with the detected encoding.\n",
    "\"\"\"\n",
    "# 2007 folder:\n",
    "reset_list()  # Clear the lists\n",
    "for filename in car_2007_names:\n",
    "    file_path = os.path.join(path_2007, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        encoding = chardet.detect(file.read())['encoding']\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        file_data = file.read()\n",
    "        add_to_list(filename, file_data)\n",
    "\n",
    "make_df(2007)\n",
    "\n",
    "# 2008 folder:\n",
    "reset_list()  # Clear the lists\n",
    "for filename in car_2008_names:\n",
    "    file_path = os.path.join(path_2008, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        encoding = chardet.detect(file.read())['encoding']\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        file_data = file.read()\n",
    "        add_to_list(filename, file_data)\n",
    "\n",
    "make_df(2008)\n",
    "\n",
    "# 2009 folder:\n",
    "reset_list()  # Clear the lists\n",
    "for filename in car_2009_names:\n",
    "    file_path = os.path.join(path_2009, filename)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        encoding = chardet.detect(file.read())['encoding']\n",
    "\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        file_data = file.read()\n",
    "        add_to_list(filename, file_data)\n",
    "\n",
    "make_df(2009)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR_NAME</th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711111</td>\n",
       "      <td>I just moved to Germany two months ago and bou...</td>\n",
       "      <td>The separate controls for the rear passengers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711112</td>\n",
       "      <td>After months of careful research and test driv...</td>\n",
       "      <td>The self-adjusting side mirrors which rotate t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711113</td>\n",
       "      <td>I'm two years into a three year lease and I lo...</td>\n",
       "      <td>Navi is easy, hands-free is great, AWD is perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711114</td>\n",
       "      <td>First luxury crossover SUV I have owned. MDX w...</td>\n",
       "      <td>AWD system, exterior styling, cargo room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711115</td>\n",
       "      <td>This is the first Japanese SUV we have had in ...</td>\n",
       "      <td>Navigation, sound system, bluetooth, comfort, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730009</td>\n",
       "      <td>I have been a loyal Volvo customer (3 Cross Co...</td>\n",
       "      <td>Safety, plenty of room, great convenience feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730010</td>\n",
       "      <td>this car is probably the best vehicle I have o...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730011</td>\n",
       "      <td>This is my first Volvo purchase and so far so ...</td>\n",
       "      <td>Leather seats, extra large trunk space (for a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730012</td>\n",
       "      <td>This is a great car....tons of power with new ...</td>\n",
       "      <td>Bi xenon headlights, AWD w/ instant traction, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730013</td>\n",
       "      <td>I recently bought an 2007 Volvo XC90 with the ...</td>\n",
       "      <td>The stares I get from women thinking I have a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18903 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CAR_NAME      DOCID  \\\n",
       "0       2007_acura_mdx  200711111   \n",
       "1       2007_acura_mdx  200711112   \n",
       "2       2007_acura_mdx  200711113   \n",
       "3       2007_acura_mdx  200711114   \n",
       "4       2007_acura_mdx  200711115   \n",
       "...                ...        ...   \n",
       "18898  2007_volvo_xc90  200730009   \n",
       "18899  2007_volvo_xc90  200730010   \n",
       "18900  2007_volvo_xc90  200730011   \n",
       "18901  2007_volvo_xc90  200730012   \n",
       "18902  2007_volvo_xc90  200730013   \n",
       "\n",
       "                                                    TEXT  \\\n",
       "0      I just moved to Germany two months ago and bou...   \n",
       "1      After months of careful research and test driv...   \n",
       "2      I'm two years into a three year lease and I lo...   \n",
       "3      First luxury crossover SUV I have owned. MDX w...   \n",
       "4      This is the first Japanese SUV we have had in ...   \n",
       "...                                                  ...   \n",
       "18898  I have been a loyal Volvo customer (3 Cross Co...   \n",
       "18899  this car is probably the best vehicle I have o...   \n",
       "18900  This is my first Volvo purchase and so far so ...   \n",
       "18901  This is a great car....tons of power with new ...   \n",
       "18902  I recently bought an 2007 Volvo XC90 with the ...   \n",
       "\n",
       "                                                FAVORITE  \n",
       "0      The separate controls for the rear passengers ...  \n",
       "1      The self-adjusting side mirrors which rotate t...  \n",
       "2      Navi is easy, hands-free is great, AWD is perf...  \n",
       "3               AWD system, exterior styling, cargo room  \n",
       "4      Navigation, sound system, bluetooth, comfort, ...  \n",
       "...                                                  ...  \n",
       "18898  Safety, plenty of room, great convenience feat...  \n",
       "18899                                                     \n",
       "18900  Leather seats, extra large trunk space (for a ...  \n",
       "18901  Bi xenon headlights, AWD w/ instant traction, ...  \n",
       "18902  The stares I get from women thinking I have a ...  \n",
       "\n",
       "[18903 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_2007_DOC\n",
    "# cars_2008_DOC\n",
    "# cars_2009_DOC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of document 2007: 18903\n",
      "number of document 2008: 15438\n",
      "number of document 2009: 7947\n"
     ]
    }
   ],
   "source": [
    "print('number of document 2007:', len(cars_2007_DOC))\n",
    "print('number of document 2008:', len(cars_2008_DOC))\n",
    "print('number of document 2009:', len(cars_2009_DOC))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='yellow'>-----------------------PART 2: PREPROCESSING-----------------------</font>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Remove punctuation and convert to lowercase letters:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]',' ', text)\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove puncutation 2007:\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(remove_punctuation)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(remove_punctuation)\n",
    "# lowercase 2007:\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(lower_case)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(lower_case)\n",
    "\n",
    "# Remove puncutation 2008:\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(remove_punctuation)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(remove_punctuation)\n",
    "# lowercase 2008:\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(lower_case)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(lower_case)\n",
    "\n",
    "# Remove puncutation 2009:\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(remove_punctuation)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(remove_punctuation)\n",
    "# lowercase 2009:\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(lower_case)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(lower_case)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Removing Numbers:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i just moved to germany two months ago and bought an 07 mdx from another military member  it has everything i could want  we just returned from a week driving through the alps and this suv is simply amazing  granted  i get to drive it much faster than i could in the states  but even at 120 mph  it was rock solid  we need the awd for the snow and the kids stay entertained with the av system  plenty of passing power and very comfortable on long trips  acuras are rare in germany and i get stares all the time by curious bavarians wondering what kind of vehicle i have  if you are in the market for a luxury suv for family touring  with cool tech toys to play with  mdx can t be beat  '"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_numbers(text):\n",
    "    res = ''\n",
    "    for char in text:\n",
    "     if not char.isdigit():\n",
    "          res += char\n",
    "          \n",
    "    return res\n",
    "cars_2007_DOC['TEXT'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_numbers 2007\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(remove_numbers)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(remove_numbers)\n",
    "# remove_numbers 2008\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(remove_numbers)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(remove_numbers)\n",
    "# remove_numbers 2009\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(remove_numbers)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i just moved to germany two months ago and bought an  mdx from another military member  it has everything i could want  we just returned from a week driving through the alps and this suv is simply amazing  granted  i get to drive it much faster than i could in the states  but even at  mph  it was rock solid  we need the awd for the snow and the kids stay entertained with the av system  plenty of passing power and very comfortable on long trips  acuras are rare in germany and i get stares all the time by curious bavarians wondering what kind of vehicle i have  if you are in the market for a luxury suv for family touring  with cool tech toys to play with  mdx can t be beat  '"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_2007_DOC['TEXT'].iloc[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Removing Stopwords:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    # Tokenize the input text\n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Remove the stop words\n",
    "    filtered_text = [word for word in word_tokens if not word in stopwords]\n",
    "\n",
    "    # Join the filtered words back into a string\n",
    "    filtered_text = ' '.join(filtered_text)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(remove_stopwords)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(remove_stopwords)\n",
    "\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(remove_stopwords)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(remove_stopwords)\n",
    "\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(remove_stopwords)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR_NAME</th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711111</td>\n",
       "      <td>moved germany months ago bought mdx military m...</td>\n",
       "      <td>separate controls rear passengers awesome cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711112</td>\n",
       "      <td>months careful research test drives bmw lexus ...</td>\n",
       "      <td>adjusting side mirrors rotate give view curb l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711113</td>\n",
       "      <td>years year lease love car thing change shape g...</td>\n",
       "      <td>navi easy hands free great awd perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711114</td>\n",
       "      <td>luxury crossover suv owned mdx won lexus cost ...</td>\n",
       "      <td>awd system exterior styling cargo room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711115</td>\n",
       "      <td>japanese suv suv yukon xl envoy xl beats perfo...</td>\n",
       "      <td>navigation sound system bluetooth comfort acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730009</td>\n",
       "      <td>loyal volvo customer cross country years feel ...</td>\n",
       "      <td>safety plenty room great convenience features ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730010</td>\n",
       "      <td>car vehicle owned feel beats fx safest suv road</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730011</td>\n",
       "      <td>volvo purchase good love exterior aesthetics i...</td>\n",
       "      <td>leather seats extra large trunk space mid size...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730012</td>\n",
       "      <td>great car tons power speed auto luxurious inte...</td>\n",
       "      <td>bi xenon headlights awd instant traction navi ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730013</td>\n",
       "      <td>recently bought volvo xc cylinder motor sluggi...</td>\n",
       "      <td>stares women thinking large income thing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18903 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CAR_NAME      DOCID  \\\n",
       "0       2007_acura_mdx  200711111   \n",
       "1       2007_acura_mdx  200711112   \n",
       "2       2007_acura_mdx  200711113   \n",
       "3       2007_acura_mdx  200711114   \n",
       "4       2007_acura_mdx  200711115   \n",
       "...                ...        ...   \n",
       "18898  2007_volvo_xc90  200730009   \n",
       "18899  2007_volvo_xc90  200730010   \n",
       "18900  2007_volvo_xc90  200730011   \n",
       "18901  2007_volvo_xc90  200730012   \n",
       "18902  2007_volvo_xc90  200730013   \n",
       "\n",
       "                                                    TEXT  \\\n",
       "0      moved germany months ago bought mdx military m...   \n",
       "1      months careful research test drives bmw lexus ...   \n",
       "2      years year lease love car thing change shape g...   \n",
       "3      luxury crossover suv owned mdx won lexus cost ...   \n",
       "4      japanese suv suv yukon xl envoy xl beats perfo...   \n",
       "...                                                  ...   \n",
       "18898  loyal volvo customer cross country years feel ...   \n",
       "18899    car vehicle owned feel beats fx safest suv road   \n",
       "18900  volvo purchase good love exterior aesthetics i...   \n",
       "18901  great car tons power speed auto luxurious inte...   \n",
       "18902  recently bought volvo xc cylinder motor sluggi...   \n",
       "\n",
       "                                                FAVORITE  \n",
       "0      separate controls rear passengers awesome cont...  \n",
       "1      adjusting side mirrors rotate give view curb l...  \n",
       "2                 navi easy hands free great awd perfect  \n",
       "3                 awd system exterior styling cargo room  \n",
       "4      navigation sound system bluetooth comfort acce...  \n",
       "...                                                  ...  \n",
       "18898  safety plenty room great convenience features ...  \n",
       "18899                                                     \n",
       "18900  leather seats extra large trunk space mid size...  \n",
       "18901  bi xenon headlights awd instant traction navi ...  \n",
       "18902           stares women thinking large income thing  \n",
       "\n",
       "[18903 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_2007_DOC"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='orange'>Tokenization and Lemmatization:</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    return nltk.word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'are'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('are')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be\tbe\tbe\tbe\tbe\t"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "for item in ['am' ,'are' ,'is','was','were']:\n",
    "    print(lemmatizer.lemmatize(item,pos='v'),end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize 2007:\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(tokenize)\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(tokenize)\n",
    "# Lemmatization 2007:\n",
    "cars_2007_DOC['TEXT'] = cars_2007_DOC['TEXT'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "cars_2007_DOC['FAVORITE'] = cars_2007_DOC['FAVORITE'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "# Tokenize 2008:\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(tokenize)\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(tokenize)\n",
    "# Lemmatization 2008:\n",
    "cars_2008_DOC['TEXT'] = cars_2008_DOC['TEXT'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "cars_2008_DOC['FAVORITE'] = cars_2008_DOC['FAVORITE'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "\n",
    "# Tokenize 2009:\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(tokenize)\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(tokenize)\n",
    "# Lemmatization 2009:\n",
    "cars_2009_DOC['TEXT'] = cars_2009_DOC['TEXT'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n",
    "cars_2009_DOC['FAVORITE'] = cars_2009_DOC['FAVORITE'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'year', 'lease', 'love', 'car', 'thing', 'change', 'shape', 'grill', 'perfect', 'great', 'performance', 'plenty', 'power', 'awd', 'skiing', 'plenty', 'room', 'baggage', 'great', 'mpg', 'suv', 'navi', 'system', 'superior', 'gm', 'suburban', 'don', 'put', 'park', 'change', 'destination', 'problem', 'gas', 'oil', 'beautiful', 'car', 'sho', 'gun', 'shield', 'grill']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR_NAME</th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711111</td>\n",
       "      <td>[moved, germany, month, ago, bought, mdx, mili...</td>\n",
       "      <td>[separate, control, rear, passenger, awesome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711112</td>\n",
       "      <td>[month, careful, research, test, drive, bmw, l...</td>\n",
       "      <td>[adjusting, side, mirror, rotate, give, view, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711113</td>\n",
       "      <td>[year, year, lease, love, car, thing, change, ...</td>\n",
       "      <td>[navi, easy, hand, free, great, awd, perfect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711114</td>\n",
       "      <td>[luxury, crossover, suv, owned, mdx, won, lexu...</td>\n",
       "      <td>[awd, system, exterior, styling, cargo, room]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711115</td>\n",
       "      <td>[japanese, suv, suv, yukon, xl, envoy, xl, bea...</td>\n",
       "      <td>[navigation, sound, system, bluetooth, comfort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18898</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730009</td>\n",
       "      <td>[loyal, volvo, customer, cross, country, year,...</td>\n",
       "      <td>[safety, plenty, room, great, convenience, fea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18899</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730010</td>\n",
       "      <td>[car, vehicle, owned, feel, beat, fx, safest, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18900</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730011</td>\n",
       "      <td>[volvo, purchase, good, love, exterior, aesthe...</td>\n",
       "      <td>[leather, seat, extra, large, trunk, space, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18901</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730012</td>\n",
       "      <td>[great, car, ton, power, speed, auto, luxuriou...</td>\n",
       "      <td>[bi, xenon, headlight, awd, instant, traction,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18902</th>\n",
       "      <td>2007_volvo_xc90</td>\n",
       "      <td>200730013</td>\n",
       "      <td>[recently, bought, volvo, xc, cylinder, motor,...</td>\n",
       "      <td>[stare, woman, thinking, large, income, thing]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18903 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              CAR_NAME      DOCID  \\\n",
       "0       2007_acura_mdx  200711111   \n",
       "1       2007_acura_mdx  200711112   \n",
       "2       2007_acura_mdx  200711113   \n",
       "3       2007_acura_mdx  200711114   \n",
       "4       2007_acura_mdx  200711115   \n",
       "...                ...        ...   \n",
       "18898  2007_volvo_xc90  200730009   \n",
       "18899  2007_volvo_xc90  200730010   \n",
       "18900  2007_volvo_xc90  200730011   \n",
       "18901  2007_volvo_xc90  200730012   \n",
       "18902  2007_volvo_xc90  200730013   \n",
       "\n",
       "                                                    TEXT  \\\n",
       "0      [moved, germany, month, ago, bought, mdx, mili...   \n",
       "1      [month, careful, research, test, drive, bmw, l...   \n",
       "2      [year, year, lease, love, car, thing, change, ...   \n",
       "3      [luxury, crossover, suv, owned, mdx, won, lexu...   \n",
       "4      [japanese, suv, suv, yukon, xl, envoy, xl, bea...   \n",
       "...                                                  ...   \n",
       "18898  [loyal, volvo, customer, cross, country, year,...   \n",
       "18899  [car, vehicle, owned, feel, beat, fx, safest, ...   \n",
       "18900  [volvo, purchase, good, love, exterior, aesthe...   \n",
       "18901  [great, car, ton, power, speed, auto, luxuriou...   \n",
       "18902  [recently, bought, volvo, xc, cylinder, motor,...   \n",
       "\n",
       "                                                FAVORITE  \n",
       "0      [separate, control, rear, passenger, awesome, ...  \n",
       "1      [adjusting, side, mirror, rotate, give, view, ...  \n",
       "2          [navi, easy, hand, free, great, awd, perfect]  \n",
       "3          [awd, system, exterior, styling, cargo, room]  \n",
       "4      [navigation, sound, system, bluetooth, comfort...  \n",
       "...                                                  ...  \n",
       "18898  [safety, plenty, room, great, convenience, fea...  \n",
       "18899                                                 []  \n",
       "18900  [leather, seat, extra, large, trunk, space, mi...  \n",
       "18901  [bi, xenon, headlight, awd, instant, traction,...  \n",
       "18902     [stare, woman, thinking, large, income, thing]  \n",
       "\n",
       "[18903 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example:\n",
    "print(cars_2007_DOC['TEXT'].iloc[2])\n",
    "cars_2007_DOC\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='yellow'>-----------------------PART 3: INVERTED INDEX-----------------------</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR_NAME</th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711111</td>\n",
       "      <td>[moved, germany, month, ago, bought, mdx, mili...</td>\n",
       "      <td>[separate, control, rear, passenger, awesome, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711112</td>\n",
       "      <td>[month, careful, research, test, drive, bmw, l...</td>\n",
       "      <td>[adjusting, side, mirror, rotate, give, view, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711113</td>\n",
       "      <td>[year, year, lease, love, car, thing, change, ...</td>\n",
       "      <td>[navi, easy, hand, free, great, awd, perfect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711114</td>\n",
       "      <td>[luxury, crossover, suv, owned, mdx, won, lexu...</td>\n",
       "      <td>[awd, system, exterior, styling, cargo, room]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007_acura_mdx</td>\n",
       "      <td>200711115</td>\n",
       "      <td>[japanese, suv, suv, yukon, xl, envoy, xl, bea...</td>\n",
       "      <td>[navigation, sound, system, bluetooth, comfort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7942</th>\n",
       "      <td>2009_volvo_c70</td>\n",
       "      <td>200919053</td>\n",
       "      <td>[vw, driver, year, talked, vw, lease, expired,...</td>\n",
       "      <td>[hardtop, roof, trunk, space, awesome, convert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7943</th>\n",
       "      <td>2009_volvo_c70</td>\n",
       "      <td>200919054</td>\n",
       "      <td>[handle, beautiful, fun, drive, surprised, lar...</td>\n",
       "      <td>[retractable, hard, top, great, operates, quic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7944</th>\n",
       "      <td>2009_volvo_c70</td>\n",
       "      <td>200919055</td>\n",
       "      <td>[excellent, exterior, interior, styling, inter...</td>\n",
       "      <td>[styling, fantastic, sound, system, big, trunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7945</th>\n",
       "      <td>2009_volvo_c70</td>\n",
       "      <td>200919056</td>\n",
       "      <td>[smooth, handling, head, turning, style, hand,...</td>\n",
       "      <td>[broad, shouldered, styling, dynamic, audio, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7946</th>\n",
       "      <td>2009_volvo_c70</td>\n",
       "      <td>200919057</td>\n",
       "      <td>[smooth, silk, shifting, manual, speed, excell...</td>\n",
       "      <td>[huge, trunk, smooth, speed, shifting, nice, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42288 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CAR_NAME      DOCID  \\\n",
       "0     2007_acura_mdx  200711111   \n",
       "1     2007_acura_mdx  200711112   \n",
       "2     2007_acura_mdx  200711113   \n",
       "3     2007_acura_mdx  200711114   \n",
       "4     2007_acura_mdx  200711115   \n",
       "...              ...        ...   \n",
       "7942  2009_volvo_c70  200919053   \n",
       "7943  2009_volvo_c70  200919054   \n",
       "7944  2009_volvo_c70  200919055   \n",
       "7945  2009_volvo_c70  200919056   \n",
       "7946  2009_volvo_c70  200919057   \n",
       "\n",
       "                                                   TEXT  \\\n",
       "0     [moved, germany, month, ago, bought, mdx, mili...   \n",
       "1     [month, careful, research, test, drive, bmw, l...   \n",
       "2     [year, year, lease, love, car, thing, change, ...   \n",
       "3     [luxury, crossover, suv, owned, mdx, won, lexu...   \n",
       "4     [japanese, suv, suv, yukon, xl, envoy, xl, bea...   \n",
       "...                                                 ...   \n",
       "7942  [vw, driver, year, talked, vw, lease, expired,...   \n",
       "7943  [handle, beautiful, fun, drive, surprised, lar...   \n",
       "7944  [excellent, exterior, interior, styling, inter...   \n",
       "7945  [smooth, handling, head, turning, style, hand,...   \n",
       "7946  [smooth, silk, shifting, manual, speed, excell...   \n",
       "\n",
       "                                               FAVORITE  \n",
       "0     [separate, control, rear, passenger, awesome, ...  \n",
       "1     [adjusting, side, mirror, rotate, give, view, ...  \n",
       "2         [navi, easy, hand, free, great, awd, perfect]  \n",
       "3         [awd, system, exterior, styling, cargo, room]  \n",
       "4     [navigation, sound, system, bluetooth, comfort...  \n",
       "...                                                 ...  \n",
       "7942  [hardtop, roof, trunk, space, awesome, convert...  \n",
       "7943  [retractable, hard, top, great, operates, quic...  \n",
       "7944  [styling, fantastic, sound, system, big, trunk...  \n",
       "7945  [broad, shouldered, styling, dynamic, audio, s...  \n",
       "7946  [huge, trunk, smooth, speed, shifting, nice, d...  \n",
       "\n",
       "[42288 rows x 4 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the data frames vertically\n",
    "all_cars_DOC = pd.concat([cars_2007_DOC, cars_2008_DOC, cars_2009_DOC], axis=0)\n",
    "all_cars_DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file\n",
    "# all_cars_DOC.to_csv('all_cars_DOC.csv', encoding='utf-8', index=False)\n",
    "# all_cars_DOC = pd.read_csv('all_cars_DOC.csv')\n",
    "# all_cars_DOC.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create a defaultdict to store the inverted index\n",
    "inv_indx = defaultdict(list)\n",
    "\n",
    "def inverted_index(col):\n",
    "\n",
    "    global inv_indx\n",
    "\n",
    "    # Create a defaultdict to store the document frequency\n",
    "    doc_freq = defaultdict(int)\n",
    "\n",
    "    # Iterate over the documents\n",
    "    for idx, text in enumerate(all_cars_DOC[col]):\n",
    "        # Get the ID of the dataframe\n",
    "        doc_id = all_cars_DOC.iloc[idx]['DOCID']\n",
    "        # Iterate over the words in the document\n",
    "        for word in set(text):\n",
    "            # Update the inverted index\n",
    "            inv_indx[word].append((doc_id, text.count(word)))\n",
    "            # Update the document frequency\n",
    "            doc_freq[word] += 1\n",
    "\n",
    "    # Sort the postings for each word by their document frequency\n",
    "    inv_indx = {word: sorted(postings, key=lambda x: x[1]) for word, postings in inv_indx.items()}\n",
    "\n",
    "    # Sort the inverted index by document frequency in ascending order\n",
    "    inv_indx = sorted(inv_indx.items(), key=lambda x: doc_freq[x[0]])\n",
    "\n",
    "    # Write the inverted index to a text file\n",
    "    with open(str(col) + '_' + 'inverted_index.txt', 'w') as f:\n",
    "        for word, postings in inv_indx:\n",
    "            f.write(word + ': ' + str(doc_freq[word]) + '\\n')\n",
    "            # tokens.extend(word) # hw2\n",
    "            # info.extend(str(doc_freq[word])) # hw2          \n",
    "            for posting in postings:\n",
    "                f.write(str(posting[0]) + ': ' + str(posting[1]) + '\\n')\n",
    "                # info.extend((str(posting[0]) + ',' + str(posting[1])))\n",
    "                \n",
    "            f.write('\\n----------------\\n')\n",
    "\n",
    "    # Print the number of tokens, maximum, minimum, and average length of the posting list\n",
    "    num_tokens = len(inv_indx)\n",
    "    # num_tokens = len(set(inv_indx)) # meeeeeeeeeeeeeeeee\n",
    "    \n",
    "    postings_lengths = [len(postings) for word, postings in inv_indx]\n",
    "    max_len = max(postings_lengths)\n",
    "    min_len = min(postings_lengths)\n",
    "    avg_len = sum(postings_lengths) / num_tokens\n",
    "    \n",
    "    print(f\"Number of Tokens for {col}:\", num_tokens)\n",
    "    print(f\"Maximum Length of Posting List for {col}:\", max_len)\n",
    "    print(f\"Minimum Length of Posting List for {col}:\", min_len)\n",
    "    print(f\"Average Length of Posting List for {col}:\", avg_len)\n",
    "\n",
    "    # Print the word with the most and least posting list\n",
    "    most_postings = max(inv_indx, key=lambda x: len(x[1]))\n",
    "    least_postings = min(inv_indx, key=lambda x: len(x[1]))\n",
    "    print(\"\\nWord with the most posting list:\", most_postings[0])\n",
    "    print(\"Word with the least posting list:\", least_postings[0])\n",
    "    print('\\n------------\\n')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Tokens for TEXT: 24713\n",
      "Maximum Length of Posting List for TEXT: 26299\n",
      "Minimum Length of Posting List for TEXT: 1\n",
      "Average Length of Posting List for TEXT: 53.621171043580304\n",
      "\n",
      "Word with the most posting list: car\n",
      "Word with the least posting list: unhooking\n",
      "\n",
      "------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calling the inverted_index function\n",
    "inverted_index('TEXT')\n",
    "# inverted_index('FAVORITE')\n",
    "\n",
    "# Inverted indexes are stored in two separate files:\n",
    "#    FAVORITE_inverted_index.txt\n",
    "#    TEXT_inverted_index.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_tokens = []\n",
    "FAVORITE_tokens = []\n",
    "def get_tokens():\n",
    "    global TEXT_tokens, FAVORITE_tokens\n",
    "     # find tokens\n",
    "    for _, row in all_cars_DOC.iterrows():\n",
    "        TEXT_tokens.extend(row['TEXT'])  \n",
    "        FAVORITE_tokens.extend(row['FAVORITE'])  \n",
    "          \n",
    "    TEXT_tokens = list(set(TEXT_tokens))\n",
    "    FAVORITE_tokens = list(set(FAVORITE_tokens))\n",
    "        \n",
    "get_tokens() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24713"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT_tokens)\n",
    "# len(FAVORITE_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# doc_freq = dict()\n",
    "# doc_id = dict()\n",
    "# term_freq = dict()\n",
    "\n",
    "# def INV_INDEX(col):\n",
    "#     global tokens, doc_freq\n",
    "    \n",
    "   \n",
    "    \n",
    "    # document frequency, document_id:\n",
    "       \n",
    "    # set all df for each token to 0\n",
    "    # for token in tokens:\n",
    "    #     doc_freq[token] = 0\n",
    "    #     doc_id[token] = []\n",
    "    #     # term_freq = 0\n",
    "    \n",
    "    # for _, row in all_cars_DOC.iterrows():\n",
    "    #     for token in set(row[col]):\n",
    "    #         doc_freq[token] += 1\n",
    "    #         doc_id[token].append(row['DOCID'])\n",
    "    #         term_freq[(row['DOCID'], token)] = row[col].count(token)\n",
    "    \n",
    "    \n",
    "    # doc_freq = dict(sorted(doc_freq.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "    # # Write the inverted index to a text file\n",
    "    # with open(str(col) + '_' + 'inv_ind_2.txt', 'w') as f:\n",
    "        \n",
    "    #     for token in tokens:\n",
    "    #         f.write(token + ': ' + str(doc_freq[token]) + '\\n')\n",
    "            \n",
    "    #         for j in range(len(doc_id[token])):\n",
    "    #              f.write(doc_id[token][j] + ': ' + str(term_freq[(doc_id[token][j], token)]) + '\\n')\n",
    "            \n",
    "    #         f.write('\\n----------------\\n')\n",
    "    \n",
    "    # print(f\"Number of Tokens for {col}:\", len(tokens))\n",
    "    \n",
    "    # max_value = max(doc_freq.values())\n",
    "    # max_pos = [key for key, value in doc_freq.items() if value == max_value]\n",
    "    # print(f\"Maximum Length of Posting List for {col}:\", max_value)\n",
    "    \n",
    "    # min_value = min(doc_freq.values())\n",
    "    # min_pos = [key for key, value in doc_freq.items() if value == min_value]\n",
    "    # print(f\"Minimum Length of Posting List for {col}:\", min_value)\n",
    "    \n",
    "    # sum_value = sum(doc_freq.values())\n",
    "    # len_posting = len(doc_freq)\n",
    "    # print(f\"Average Length of Posting List for {col}:\", sum_value/len_posting)\n",
    "\n",
    "    # print(\"\\nWord with the most posting list:\", max_pos[0])\n",
    "    # print(\"Word with the least posting list:\", min_pos[0])        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INV_INDEX('TEXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(tokens))\n",
    "# # print(len(set(tokens)))\n",
    "# print(tokens[200:400])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='lightgreen'>HW-2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def w_td(tf_td):\n",
    "    return 1 + math.log10(tf_td) if tf_td > 0 else 0\n",
    "\n",
    "def w_tq(q, term):\n",
    "    tf_tq = q.count(term)\n",
    "    return 1 + math.log10(tf_tq) if tf_tq > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len_docs = all_cars_DOC.shape[0]\n",
    "pos_id = []\n",
    "for position,doc_id in enumerate(all_cars_DOC['DOCID']):\n",
    "    pos_id.append(tuple([doc_id, position])) \n",
    "    \n",
    "pos_id = dict(pos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_indx = dict(inv_indx)\n",
    "# inv_indx['car']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_list_item(token_list):\n",
    "    return sum([len(word) for word in token_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "for _, row in all_cars_DOC.iterrows():\n",
    "    scores[row['DOCID']] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "\n",
    "def cosine_score(q, col, k):\n",
    "    global scores\n",
    "    for _, row in all_cars_DOC.iterrows():\n",
    "        scores[row['DOCID']] = 0\n",
    "    \n",
    "    for term in nltk.word_tokenize(q):\n",
    "        w_t_q = w_tq(q, term)\n",
    "        pos_list_t = inv_indx[term]\n",
    "        \n",
    "        for pair in pos_list_t:\n",
    "            w_t_d = w_td(tf_td=pair[1])\n",
    "            scores[pair[0]] += w_t_d * w_t_q\n",
    "        \n",
    "    for _, row in all_cars_DOC.iterrows():\n",
    "        if len(row[col]) != 0:\n",
    "            #  scores[row['DOCID']] =  scores[row['DOCID']] / len(row[col])\n",
    "             scores[row['DOCID']] =  scores[row['DOCID']] / length_list_item(row[col])\n",
    "    \n",
    "    # scores.sort(reverse=True)\n",
    "    scores = dict(sorted(scores.items(), key=lambda x:x[1], reverse=True))\n",
    "    keys = list(scores)[0:k] # top-k\n",
    "    for key in keys:\n",
    "        print('doc id:', key)\n",
    "        print('file_name:', all_cars_DOC[all_cars_DOC['DOCID'] == key][[\"CAR_NAME\"]].to_string(index=False,header=False))\n",
    "        print('content:', all_cars_DOC[all_cars_DOC['DOCID'] == key][[\"TEXT\"]].to_string(index=False,header=False))\n",
    "        print('Relevancy:', scores[key])\n",
    "        print('---------')\n",
    "        \n",
    "\n",
    "\n",
    "    # return scores[0:10]  # top-k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc id: 200729953\n",
      "file_name: 2007_volvo_xc70\n",
      "content: [love, volvo, sweden, safe, comfortable, sturdy]\n",
      "Relevancy: 0.027777777777777776\n",
      "---------\n",
      "doc id: 200730005\n",
      "file_name: 2007_volvo_xc90\n",
      "content: [volvo, make, world, safest, car, fun, easy, drive, suv]\n",
      "Relevancy: 0.02631578947368421\n",
      "---------\n",
      "doc id: 200712117\n",
      "file_name: 2007_bmw_3_series\n",
      "content: [awesome, car, fast, fun, drive, traded, volvo, sr, awd, make, volvo, bus]\n",
      "Relevancy: 0.026020599913279624\n",
      "---------\n",
      "doc id: 200826201\n",
      "file_name: 2008_volkswagen_passat\n",
      "content: [volvo, turbo, comparison, quietness, pep, comfort]\n",
      "Relevancy: 0.02564102564102564\n",
      "---------\n",
      "doc id: 200729949\n",
      "file_name: 2007_volvo_xc70\n",
      "content: [great, fun, drive, enjoying, technology, volvo, year]\n",
      "Relevancy: 0.025\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "#     query = input('Enter your query(exit to stop):')\n",
    "\n",
    "#     if query.lower() == 'exit':\n",
    "#         break\n",
    "    \n",
    "#     cosine_score(query)\n",
    "\n",
    "# query = input('Enter your query(exit to stop):')\n",
    "# cosine_score(query)\n",
    "col = 'TEXT'\n",
    "text = \"volvo\"\n",
    "cosine_score(text, col, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAR_NAME</th>\n",
       "      <th>DOCID</th>\n",
       "      <th>TEXT</th>\n",
       "      <th>FAVORITE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2009_acura_mdx</td>\n",
       "      <td>200911133</td>\n",
       "      <td>[car]</td>\n",
       "      <td>[comfort, mode, voice, command, bluetooth, link]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CAR_NAME      DOCID   TEXT  \\\n",
       "22  2009_acura_mdx  200911133  [car]   \n",
       "\n",
       "                                            FAVORITE  \n",
       "22  [comfort, mode, voice, command, bluetooth, link]  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_cars_DOC[all_cars_DOC['DOCID'] == '200911133'][[\"CAR_NAME\", 'TEXT']].to_string(index=False,header=False)\n",
    "all_cars_DOC[all_cars_DOC['DOCID'] == '200911133']\n",
    "# print(str(s))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2 - HW-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_name(words):\n",
    "    # Remove numbers from words\n",
    "    words = [re.sub(r'\\d', '', word) for word in words]\n",
    "\n",
    "    # Remove dashes from beginning and end of words\n",
    "    words = [word.strip('_') for word in words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "names_2007 = simple_name(car_2007_names)\n",
    "names_2008 = simple_name(car_2008_names)\n",
    "names_2009 = simple_name(car_2009_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dict()\n",
    "\n",
    "def cosine_score_2(q, col, n_related):\n",
    "    global scores\n",
    "    \n",
    "    for _, row in all_cars_DOC.iterrows():\n",
    "        scores[row['DOCID']] = 0\n",
    "    \n",
    "    if col == 'TEXT':\n",
    "        for term in q:\n",
    "            if term  in TEXT_tokens:\n",
    "                # continue  \n",
    "                w_t_q = w_tq(q, term)\n",
    "                pos_list_t = inv_indx[term]\n",
    "    \n",
    "                for pair in pos_list_t:\n",
    "                    w_t_d = w_td(tf_td=pair[1])\n",
    "                    scores[pair[0]] += w_t_d * w_t_q              \n",
    "    elif col == 'FAVORITE':\n",
    "        for term in q:\n",
    "            if term  in FAVORITE_tokens:    \n",
    "                # continue        \n",
    "                w_t_q = w_tq(q, term)\n",
    "                pos_list_t = inv_indx[term]\n",
    "    \n",
    "                for pair in pos_list_t:\n",
    "                    w_t_d = w_td(tf_td=pair[1])\n",
    "                    scores[pair[0]] += w_t_d * w_t_q\n",
    "        \n",
    "        \n",
    "    \n",
    "    for _, row in all_cars_DOC.iterrows():\n",
    "        if len(row[col]) != 0:\n",
    "            #  scores[row['DOCID']] =  scores[row['DOCID']] / len(row[col])\n",
    "             scores[row['DOCID']] =  scores[row['DOCID']] / length_list_item(row[col])\n",
    "    \n",
    "  \n",
    "    # Write the inverted index to a text file\n",
    "    with open(str(col) + '_' + 'Evaluation.txt', 'a') as f:\n",
    "        f.write(f'Query: {q}\\n')\n",
    "        # scores.sort(reverse=True)\n",
    "        scores = dict(sorted(scores.items(), key=lambda x:x[1], reverse=True))\n",
    "        for k in [1, 5, 10]:\n",
    "            keys = list(scores)[0:k] # top-k\n",
    "            n_related_retrieved_docs = 0\n",
    "            f.write(f'k = {k}\\n')\n",
    "            for key in keys:  \n",
    "                f.write(f'doc id: {key}\\n')\n",
    "                file_name = all_cars_DOC[all_cars_DOC['DOCID'] == key][[\"CAR_NAME\"]].to_string(index=False,header=False)\n",
    "                f.write(f'file_name:{file_name}\\n')\n",
    "                file_name = simple_name([file_name])\n",
    "                file_name = file_name[0]\n",
    "                file_name = file_name.split('_')\n",
    "                if file_name == q:\n",
    "                    n_related_retrieved_docs += 1\n",
    "                content = all_cars_DOC[all_cars_DOC['DOCID'] == key][[\"TEXT\"]].to_string(index=False,header=False)    \n",
    "                f.write(f'content: {content}')\n",
    "                f.write('\\n')\n",
    "                f.write(f'Relevancy:{scores[key]}\\n')\n",
    "                f.write('---------\\n')\n",
    "            \n",
    "            f.write(f'P@{k}: {n_related_retrieved_docs/k}\\n')\n",
    "            f.write(f'R@{k}: {n_related_retrieved_docs/n_related}\\n')\n",
    "            f.write('\\n===================================================\\n===================================================\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete files content\n",
    "with open('TEXT_Evaluation.txt', 'w') as f:\n",
    "    pass\n",
    "\n",
    "with open('FAVORITE_Evaluation.txt', 'w') as f:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = []\n",
    "all_names.extend(names_2007)\n",
    "all_names.extend(names_2008)\n",
    "all_names.extend(names_2009)\n",
    "all_names = list(set(all_names))\n",
    "\n",
    "for col in ['TEXT', 'FAVORITE']:\n",
    "    for name in all_names:\n",
    "        n_related = all_cars_DOC[all_cars_DOC['CAR_NAME'].str.contains(name, case=False)][['CAR_NAME']].drop_duplicates().shape[0]\n",
    "        if n_related == 0:\n",
    "            continue\n",
    "        query = name.split('_')\n",
    "        cosine_score_2(query, col, n_related)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write list to file\n",
    "with open('all_names.txt', 'w') as fp:\n",
    "    for name in all_names:\n",
    "        fp.write(name + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='skyblue'>FINISH</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
